{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare FSE/VarBugs\n",
    "\n",
    "This portion of the notebook allows you to compare the results between the sampling-based baseline and the desugared analysis results. This will print out number of results from analyzing desugared code, the number of baselines, and the overlap between them.\n",
    "\n",
    "To use this portion of the notebook, please set \"result_location\" to the location of the desugared results, and \"baseline_location\" to the location of the sampling-based baseline results."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T16:43:46.724365Z",
     "start_time": "2024-01-27T16:43:46.617781Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:00<00:00, 58743.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of baseline results: 85\n",
      "Number of desugared results: 21\n",
      "Number of feasible desugared results: 21\n",
      "Number of exact matched baselines: 0\n",
      "Number of partially matched baselines: 0\n",
      "Number of unmatched baselines: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Set Baseline and Experiment\n",
    "result_location = \"/Users/austin/git/Sugarlyzer/results.json\"\n",
    "baseline_location = \"/Users/austin/git/Sugarlyzer/baseline.json\"\n",
    "\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "\n",
    "def _default(self, obj):\n",
    "    return getattr(obj.__class__, \"to_json\", _default.default)(obj)\n",
    "\n",
    "_default.default = JSONEncoder().default\n",
    "JSONEncoder.default = _default\n",
    "\n",
    "import logging\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "with open(baseline_location) as f:\n",
    "    baselines = json.load(f)\n",
    "\n",
    "with open(result_location) as f:\n",
    "    experimental_results = json.load(f)\n",
    "\n",
    "lonely_baselines = copy.deepcopy(baselines)\n",
    "lonely_experimental_results = copy.deepcopy(experimental_results)\n",
    "\n",
    "class IntRange:\n",
    "    def __init__(self, lower_bound_inclusive, upper_bound_exclusive):\n",
    "        self.lower_bound_inclusive = lower_bound_inclusive\n",
    "        self.upper_bound_exclusive = upper_bound_exclusive\n",
    "\n",
    "    def __contains__(self, item):\n",
    "        return isinstance(item, int) and (self.lower_bound_inclusive <= item < self.upper_bound_exclusive)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"IntRange({self.lower_bound_inclusive, self.upper_bound_exclusive})\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"[{self.lower_bound_inclusive}:{self.upper_bound_exclusive})\"\n",
    "\n",
    "    def to_json(self):\n",
    "        return str(self)\n",
    "\n",
    "\n",
    "for e in experimental_results:\n",
    "    toks = e['original_line'].split(':')\n",
    "    try:\n",
    "        e['original_line'] = IntRange(int(toks[0]), int(toks[1]) + 1)\n",
    "    except Exception as ex:\n",
    "        e['original_line'] = []\n",
    "    #print('\\t'.join([\"experimental\", *[str(s) for s in e.values()]]).replace(\"\\n\", \"\"))\n",
    "\n",
    "    if e['function_line_range'] == 'ERROR':\n",
    "        e['function_line_range'] = []\n",
    "    else:\n",
    "        toks = e['function_line_range'].split(':')\n",
    "        try:\n",
    "            e['function_line_range'] = IntRange(int(toks[1]), int(toks[2]) + 1)\n",
    "        except Exception as ex:\n",
    "            logging.exception(f\"e was {e}\")\n",
    "    e['presence_condition'] = str(e['presence_condition'])\n",
    "\n",
    "import tqdm\n",
    "\n",
    "def match_stats(baseline_result: dict, experimental_result: dict) -> Tuple:\n",
    "    \"\"\"\n",
    "    Returns a vector of different match information.\n",
    "    (a, b, c)\n",
    "    a = True iff baseline and experimental have the same line number, message, and file.\n",
    "    b = True iff baseline and experimental have the same message, file, and baseline is within experimental's function scope.\n",
    "    c = True iff baseline's configuration is compatible with experimental's presence condition.\n",
    "    \"\"\"\n",
    "\n",
    "    a = (baseline_result['sanitized_message'].lstrip().rstrip() == experimental_result['sanitized_message'].lstrip().rstrip() and \\\n",
    "         baseline_result['input_line'] in experimental_result['original_line'] and\\\n",
    "         baseline_result['input_file'].split('.')[0] == experimental_result['input_file'].split('.')[0])\n",
    "\n",
    "    b = (baseline_result['sanitized_message'].lstrip().rstrip() == experimental_result['sanitized_message'].lstrip().rstrip() and \\\n",
    "         baseline_result['input_line'] in experimental_result['function_line_range'] and\\\n",
    "         baseline_result['input_file'].split('.')[0] == experimental_result['input_file'].split('.')[0])\n",
    "\n",
    "    c = False\n",
    "\n",
    "    if experimental_result['feasible'] and 'Or(None' not in experimental_result['presence_condition'] and experimental_result['presence_condition'] not in ['Or(None)', 'None'] and (a or b):  # Don't bother doing this expensive step when the file and line number are different.\n",
    "        baseline_var_mapping = {}\n",
    "        for var in baseline_result['configuration']:\n",
    "            if type(var) is str:\n",
    "                if var.startswith('DEF'):\n",
    "                    baseline_var_mapping[re.sub(r\"^(DEF_.*)\", r\"\\1\", var)] = True\n",
    "                elif var.startswith('UNDEF'):\n",
    "                    baseline_var_mapping[re.sub(r\"^UN(DEF_.*)\", r\"\\1\", var)] = False\n",
    "                else:\n",
    "                    raise RuntimeError(f\"Don't know how to handle variable {var}\")\n",
    "\n",
    "        s = Solver()\n",
    "        for var, val in baseline_var_mapping.items():\n",
    "            var = Bool(var)\n",
    "            if val:\n",
    "                s.add(var)\n",
    "            else:\n",
    "                s.add(Not(var))\n",
    "\n",
    "        for mat in re.findall(\"DEF_[a-zA-Z0-9_]+\", experimental_result['presence_condition']):\n",
    "            exec(f\"{mat} = Bool('{mat}')\")\n",
    "           \n",
    "        for mat in re.findall(\"USE_[a-zA-Z0-9_]+\", experimental_result['presence_condition']):\n",
    "            exec(f\"{mat} = Int('{mat}')\")\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                s.add(eval(experimental_result['presence_condition']))  # TODO Definitely need to do more transformation here.\n",
    "                break\n",
    "            except NameError as ne:\n",
    "                var = re.search(\"name '(.*)' is not defined\", str(ne))\n",
    "                exec(f\"{var.group(1)} = Int('{var.group(1)}')\")\n",
    "        c = s.check() == sat\n",
    "    return a, b, c\n",
    "\n",
    "def tupleize(func, args): return func(*args), tuple(args)\n",
    "\n",
    "summary = {}\n",
    "\n",
    "# Note that results depend on the order of keys in this dictionary, because once we find a match_stats for one level we do not keep searching for the next.\n",
    "#  E.g., for a given report, we will first look for results with which it has a (True, True, True) report. If it has one, we do not continue searching for\n",
    "#  matches for (False, True, True), (True, False, True), etc.\n",
    "result_hierarchy = {(True, True, True): 0, (False, True, True): 0, (True, False, True): 0, (True, True, False): 0, (False, True, False): 0, (False, False, True): 0, (True, False, False): 0, (False, False, False): 0}\n",
    "\n",
    "report = []\n",
    "for b in tqdm.tqdm(baselines):\n",
    "    # Results are (baseline, desugared, match tuple)\n",
    "    results = [(b, e, match_stats(b, e)) for e in experimental_results]\n",
    "    found = False\n",
    "    for r in result_hierarchy.keys():\n",
    "        for res in results:\n",
    "            if res[2] == r:\n",
    "                found = True\n",
    "                result_hierarchy[r] += 1\n",
    "                # -----\n",
    "                # Here is where you compile information about any specific reports you need. This block of code\n",
    "                # iterates through all baselines and finds the highest level of matching that is available.\n",
    "                # So, for example, if you wanted to collect all of the unmatched originals, you would uncomment out this line of code:\n",
    "                #\n",
    "                if (r != (True, True, True) and r != (False, True, True)):\n",
    "                    report.append(res[0])\n",
    "                break # DO NOT DELETE THE BREAK!\n",
    "        if found:\n",
    "            break\n",
    "\n",
    "print(f\"Number of baseline results: {len(baselines)}\")\n",
    "print(f\"Number of desugared results: {len(experimental_results)}\")\n",
    "print(f\"Number of feasible desugared results: {len(list(filter(lambda e: e['feasible'], experimental_results)))}\")\n",
    "print(f\"Number of exact matched baselines: {result_hierarchy[(True, True, True)]}\")\n",
    "print(f\"Number of partially matched baselines: {result_hierarchy[False, True, True]}\")\n",
    "print(\n",
    "    f\"Number of unmatched baselines: {sum(v for k, v in result_hierarchy.items() if k not in [(True, True, True), (False, True, True)])}\")"
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Time Analysis\n",
    "This part of the notebook will compute the total time the analysis took, including both desugaring time and the analysis time.\n",
    "This requires the log files produced by Sugarlyzer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Time: 1m\n",
      "Desugaring time: 12m\n"
     ]
    }
   ],
   "source": [
    "log_file = \"/Users/austin/Downloads/sugarlyzerTiming/sugarlyzerRes/clang/axtls/log.txt\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "dtime = 0\n",
    "atime = 0\n",
    "with open(log_file,'r') as i:\n",
    "    for line in i.readlines():\n",
    "        line = line.lstrip().rstrip()\n",
    "        if 'Analyzing file' in line and ' took ' in line:\n",
    "            res = re.search(r'took (\\d+\\.\\d+)s',line)\n",
    "            if res != None:\n",
    "                atime += float(res.group(1))\n",
    "            \n",
    "        elif ' desugared in time:' in line:\n",
    "            res = re.search(r' desugared in time:(\\d+\\.\\d+)',line)\n",
    "            if res != None:\n",
    "                dtime += float(res.group(1))\n",
    "            \n",
    "print (f'Analysis Time: {int(atime/60)}m\\nDesugaring time: {int(dtime/60)}m')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:41:36.802662Z",
     "start_time": "2024-01-27T16:41:36.617115Z"
    }
   },
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
